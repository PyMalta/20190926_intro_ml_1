{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:46:41.555326Z",
     "start_time": "2019-08-23T12:46:39.123027Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "# pip install graphviz\n",
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:46:41.559851Z",
     "start_time": "2019-08-23T12:46:41.556933Z"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18,\n",
    "                            'lines.linewidth' : 3,\n",
    "                            'figure.figsize' : [15, 5],\n",
    "                            'lines.markersize': 10})\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:46:41.571474Z",
     "start_time": "2019-08-23T12:46:41.561829Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('./00_data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:46:42.837951Z",
     "start_time": "2019-08-23T12:46:42.822718Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some quick data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:46:52.686603Z",
     "start_time": "2019-08-23T12:46:52.553317Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot('Survived', data=df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that not many passengers survived the accident.\n",
    "\n",
    "Out of 891 passengers in training set, only around 350 survived i.e Only 38.4% of the total training set survived the crash. We need to dig down more to get better insights from the data and see which categories of the passengers did survive and who didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:47:14.484764Z",
     "start_time": "2019-08-23T12:47:14.344880Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot('Sex', hue='Survived', data=df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of men on the ship is lot more than the number of women. Still the number of women saved is almost twice the number of males saved. The survival rates for a **women on the ship is around 75% while that for men in around 18-19%.**\n",
    "\n",
    "I guess the saying **woman and children first** did apply in the Titanic and it was a Hollywood stunt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:47:23.054607Z",
     "start_time": "2019-08-23T12:47:22.906378Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot('Pclass', hue='Survived', data=df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People say **Money Can't Buy Everything**. But we can clearly see that Passenegers Of Pclass 1 were given a very high priority while rescue. Even though the the number of Passengers in Pclass 3 were a lot higher, still the number of survival from them is very low, somewhere around **25%**.\n",
    "\n",
    "For Pclass 1 %survived is around **63%** while for Pclass2 is around **48%**. So money and status matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:47:32.669842Z",
     "start_time": "2019-08-23T12:47:32.512803Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot('Embarked', hue='Survived', data=df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh! So people who embarked from C (Cherbourg) and Q (Queenstown) where more likely to survive then those that boarded from S (Southampton)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputing missing data\n",
    "Looking at our Titanic dataset, the feature for **cabin** clearly indicates that we have `NaN` values. We need to handle these and any other null columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:47:40.980494Z",
     "start_time": "2019-08-23T12:47:40.805274Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_titanic.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:47:52.318654Z",
     "start_time": "2019-08-23T12:47:52.302382Z"
    }
   },
   "outputs": [],
   "source": [
    "def missingValues(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False) # getting the sum of null values and ordering\n",
    "    percent = (data.isnull().sum() / data.isnull().count() * 100).sort_values(ascending=False)  #getting the percent and order of null\n",
    "    dt = pd.concat([total, percent], axis=1,keys=['Total','Percent'])  # Concatenating the total and percent\n",
    "    return dt\n",
    "missingValues(df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 3 types of missing information:\n",
    "- **cabin** has 77% missing....not sure what information it can give us\n",
    "- **age** we can maybe fill in the most common.....\n",
    "- **embarked** & **fare**\n",
    "    - we could delete and not loose too much info...only 0.15% and 0.07%\n",
    "    - we could inpute with the most common embarkation port or mean_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.913718Z",
     "start_time": "2019-08-22T11:49:17.908351Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop cabin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.918783Z",
     "start_time": "2019-08-22T11:49:17.915207Z"
    }
   },
   "outputs": [],
   "source": [
    "# inpute mean age - 29.69 seems about right\n",
    "np.mean(df_titanic['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['Age'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.931226Z",
     "start_time": "2019-08-22T11:49:17.926123Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.936863Z",
     "start_time": "2019-08-22T11:49:17.932730Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic['Age'].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.943000Z",
     "start_time": "2019-08-22T11:49:17.938442Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean fare\n",
    "df_titanic['Fare'][ df_titanic['Fare'].isnull()] = round(np.mean(df_titanic['Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.948100Z",
     "start_time": "2019-08-22T11:49:17.944335Z"
    }
   },
   "outputs": [],
   "source": [
    "# inpute most common embarkation port\n",
    "from collections import Counter\n",
    "Counter(df_titanic['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.955877Z",
     "start_time": "2019-08-22T11:49:17.950018Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.963153Z",
     "start_time": "2019-08-22T11:49:17.958185Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(df_titanic['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.980031Z",
     "start_time": "2019-08-22T11:49:17.964957Z"
    }
   },
   "outputs": [],
   "source": [
    "missingValues(df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types\n",
    "**Categorical Features:**\n",
    "A categorical variable is one that has two or more categories and each value in that feature can be categorised by them. For example, gender is a categorical variable having two categories (male and female). Now we cannot sort or give any ordering to such variables. They are also known as Nominal Variables.\n",
    "\n",
    "Categorical Features in the dataset: **Sex, Embarked**.\n",
    "\n",
    "**Ordinal Features:**\n",
    "An ordinal variable is similar to categorical values, but the difference between them is that we can have relative ordering or sorting between the values. For example: If we have a feature like Height with values Tall, Medium, Short, then Height is a ordinal variable. Here we can have a relative sort in the variable.\n",
    "\n",
    "Ordinal Features in the dataset: **PClass**\n",
    "\n",
    "\n",
    "**Continous Feature:**\n",
    "A feature is said to be continous if it can take values between any two points or between the minimum or maximum values in the features column.\n",
    "\n",
    "Continous Features in the dataset: **Age, Fare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:17.994135Z",
     "start_time": "2019-08-22T11:49:17.981830Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "### Sex - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.000118Z",
     "start_time": "2019-08-22T11:49:17.996088Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(df_titanic['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.032979Z",
     "start_time": "2019-08-22T11:49:18.017818Z"
    }
   },
   "outputs": [],
   "source": [
    "## use preprocessing LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T09:36:04.616671Z",
     "start_time": "2019-08-21T09:36:04.614548Z"
    }
   },
   "source": [
    "### Embarked - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.039647Z",
     "start_time": "2019-08-22T11:49:18.034847Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(df_titanic['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.047804Z",
     "start_time": "2019-08-22T11:49:18.041918Z"
    }
   },
   "outputs": [],
   "source": [
    "## use preprpcessing OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.053501Z",
     "start_time": "2019-08-22T11:49:18.049746Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe_fitted.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.066747Z",
     "start_time": "2019-08-22T11:49:18.055398Z"
    }
   },
   "outputs": [],
   "source": [
    "df_embarked = pd.DataFrame(ohe_fitted.transform(df_titanic[['Embarked']]),\n",
    "                           columns= [ 'Embarked_{}'.format(ii) for ii in ohe_fitted.categories_[0].tolist()]\n",
    "                          )\n",
    "df_embarked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.084709Z",
     "start_time": "2019-08-22T11:49:18.068558Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.concat([ df_titanic.drop(['Embarked'], axis=1), df_embarked], axis=1)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Data\n",
    "What about **pclass** ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continous Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:18:36.353156Z",
     "start_time": "2019-08-20T10:18:36.347897Z"
    }
   },
   "source": [
    "Sometimes our observations will be very unevenly distributed for a given feature. For example, *ticket* is roughly exponentially distributed. In cases like these it can be useful to transform the values of our features or our target to better highlight trends or to allow for use of models that might not otherwise be applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.286727Z",
     "start_time": "2019-08-22T11:49:18.086335Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotDist(data):\n",
    "    sns.distplot(data, hist=True, kde=True, bins=20, color = 'darkblue', \n",
    "                 hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4})\n",
    "plotDist(df_titanic['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.298740Z",
     "start_time": "2019-08-22T11:49:18.289492Z"
    }
   },
   "outputs": [],
   "source": [
    "## use sklearn.preprocessing StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss_transformed = ss.fit_transform(df_titanic[['Age']])\n",
    "ss_transformed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.517949Z",
     "start_time": "2019-08-22T11:49:18.300789Z"
    }
   },
   "outputs": [],
   "source": [
    "plotDist(ss_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.530874Z",
     "start_time": "2019-08-22T11:49:18.519373Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.534755Z",
     "start_time": "2019-08-22T11:49:18.532452Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic['Age']= ss_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.547383Z",
     "start_time": "2019-08-22T11:49:18.536265Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler\n",
    "Another technique used to scale data is [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)\n",
    "- scaling each feature to a given range\n",
    "- *sensitive to outliers*\n",
    "\n",
    "Formal definition for MinMaxScaler is given by: $$ x'_i = \\frac{x_i-x_{min}}{x_{max} - x_{min}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In a Nutshell:**\n",
    "\n",
    "**You probably won't go wrong if you use `StandardScaler` to scale your features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready up for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.562010Z",
     "start_time": "2019-08-22T11:49:18.549203Z"
    }
   },
   "outputs": [],
   "source": [
    "df_target = df_titanic['Survived']\n",
    "# drop unwanted/redundant columns\n",
    "df_titanic.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.568568Z",
     "start_time": "2019-08-22T11:49:18.563795Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(df_titanic)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:49:18.574668Z",
     "start_time": "2019-08-22T11:49:18.570251Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_target\n",
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T12:08:58.732901Z",
     "start_time": "2019-08-22T12:08:58.711744Z"
    }
   },
   "outputs": [],
   "source": [
    "# save for later user\n",
    "df_titanic.to_csv('./00_data/titanic_X.csv', index=False)\n",
    "y.to_csv('./00_data/titanic_y.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:17.602079Z",
     "start_time": "2019-08-21T13:44:17.588856Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:17.607138Z",
     "start_time": "2019-08-21T13:44:17.603673Z"
    }
   },
   "outputs": [],
   "source": [
    "print('X_train : {}'.format(X_train.shape))\n",
    "print('y_train : {}'.format(y_train.shape))\n",
    "print('X_test : {}'.format(X_test.shape))\n",
    "print('y_test : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to our first model - Decision Trees\n",
    "- both classification or regression.\n",
    "- also outlier detection. \n",
    "\n",
    "The trained models resemble a tree, complete with branches and nodes. \n",
    "\n",
    "The model is essentially a series of questions with yes or no answers,\n",
    "- resulting tree structure contains all the combination of responses.\n",
    "\n",
    "Tree based models are popular:\n",
    "- mimic human decision making process, \n",
    "- work well for a large class of problems, \n",
    "- naturally handle multiclassification, and \n",
    "- handle a mix of categorical and numerical data. \n",
    "- easy to understand and explain : good explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training decision tree classifiers\n",
    "The best way to understand a decision tree is to construct one and visualize it. We'll train a decision tree classifier on the iris data set and visualize the tree with the Graphviz package. The iris data set is a famous data set of 150 observations of three different iris species: setosa, versicolor, and virginica. Each observation has measurements of the petal length and width and sepal length and width, for a total of four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:18.065638Z",
     "start_time": "2019-08-21T13:44:17.608792Z"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "## use DecisionTreeClassifier of depth 2. fit(X_train, y_train)\n",
    "\n",
    "# train decision tree\n",
    "tree\n",
    "\n",
    "\n",
    "# visual tree\n",
    "graphviz.Source(export_graphviz(tree, \n",
    "                                out_file=None,\n",
    "                                feature_names=np.array(df_titanic.columns.tolist()),\n",
    "                                class_names=np.array(['0','1'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the model resembles an upside down tree and each box represents a node in the tree. Printed in each box is\n",
    "\n",
    "* **samples**: the number of observations in the node.\n",
    "* **Gini**: a measure of node purity.\n",
    "* **value**: the distribution of observations in each class.\n",
    "* **class**: the most common label in the node.\n",
    "\n",
    "At the top of the tree is the __root node__. This node is _split_ to form two branches. Observations that satisfy the criterion printed at the top of the box are moved to one branch while the rest to the other. You can view a decision tree as a model that is making partitions in a space that contains your training data. The partitions are chosen to separate the different classes. For the tree displayed above, node splits were chosen to lead to an overall reduction of the Gini metric, discussed further in the next section. The nodes that do not branch off are called __terminal nodes__ or __leaves__.\n",
    "\n",
    "With a trained tree, predictions are made on an observation by starting at the root and following the path as a result of the criterion in each node. Once at a leaf, the predicted class is the class with the plurality. For example, if an observation has **sex** of 0 (<=0.5) and **pclass** of 0,1,2, it will reside in the left most leaf in the figure. \n",
    "\n",
    "Our trained tree model only makes splits using three features, **sex**, **pclass** and **age** making it easy to visualize our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T10:24:26.012569Z",
     "start_time": "2019-08-21T10:24:26.001937Z"
    }
   },
   "source": [
    "### Gini impurity\n",
    "- node impurity\n",
    "- probability of misclassifying an observation if it were randomly labeled\n",
    "\n",
    "DT will node split that result in reducing the Gini metric. The equation for the Gini impurity for node $m$ is\n",
    "\n",
    "$$ G_m = \\sum_k p_{mk} (1 - p_{mk}), $$\n",
    "\n",
    "where $p_{mk}$ is the fraction of observations of class $k$ in node $m$. \n",
    "\n",
    "Consider two cases where a node has 10 observations belonging to two classes:\n",
    "* Case 1: [5, 5]\n",
    "$$ G = \\frac{5}{10} \\left(1 - \\frac{5}{10}\\right) + \\frac{5}{10} \\left(1 - \\frac{5}{10}\\right) = 0.5 $$\n",
    "* Case 2: [10, 0]\n",
    "$$ G = \\frac{10}{10} \\left(1 - \\frac{10}{10}\\right) + \\frac{0}{10} \\left(1 - \\frac{0}{10}\\right) = 0 $$\n",
    "\n",
    "The greater the node purity, the lower the Gini metric. See the plot below of how Gini varies with $p_{mk}$ when there are two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:54:55.917883Z",
     "start_time": "2019-08-23T12:54:55.648673Z"
    }
   },
   "outputs": [],
   "source": [
    "p = np.linspace(1E-6, 1-1E-6, 100)\n",
    "gini = p*(1-p) + (1-p)*p\n",
    "\n",
    "plt.plot(p, gini)\n",
    "plt.xlabel('$p$')\n",
    "plt.ylabel('Gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "\n",
    "In chemistry, entropy is a measure of the amount of disorder in your system. \n",
    "\n",
    "The equation for entropy of node $m$ is\n",
    "\n",
    "$$ H_m = -\\sum_{k} p_{mk} \\log_2(p_{mk}).$$\n",
    "\n",
    "Using the same two cases as before when calculating the Gini metric, the entropy is equal to\n",
    "\n",
    "* Case 1: [5, 5]\n",
    "$$ H = -\\left[\\frac{5}{10} \\log_2 \\left(\\frac{5}{10}\\right) + \\frac{5}{10} \\log_2 \\left(\\frac{5}{10}\\right)\\right] = 1  $$\n",
    "* Case 2: [10, 0]\n",
    "$$ H = -\\left[\\frac{10}{10} \\log_2 \\left(\\frac{10}{10}\\right) + \\frac{0}{10} \\log_2 \\left(\\frac{0}{10}\\right)\\right] = 0 $$\n",
    "\n",
    "Similar to the Gini impurity, a more pure node will have lower entropy. Since entropy and Gini impurity are very similar metrics, using either will not make any substantial difference in your classifier. \n",
    "\n",
    "By default, the `DecisionTreeClassifier` class uses the Gini metric but can be switched to entropy by setting `criterion='entropy'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Hyperparameters\n",
    "\n",
    "| Decision Tree Hyperparameters | Description |\n",
    "|:---:|---|\n",
    "|max_depth| The maximum depth of the tree |\n",
    "|max_features|The number of features to consider when deciding the best split|\n",
    "|min_samples_split|Minimum number of samples to consider a split on an internal node|\n",
    "|min_samples_leaf|Minimum number of samples required for a leaf (terminal node)|\n",
    "\n",
    "- `scikit-learn` documentation or notebook documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:18.339353Z",
     "start_time": "2019-08-21T13:44:18.334997Z"
    }
   },
   "outputs": [],
   "source": [
    "## import DecisionTreeClassifier\n",
    "## define max_depth 3, max_features=2, min_split=10, min_leaf=20\n",
    "## dtc_fitted, dtc_pred, dtc_pred_proba\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:18.344516Z",
     "start_time": "2019-08-21T13:44:18.340969Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:18.353912Z",
     "start_time": "2019-08-21T13:44:18.345867Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:18.373107Z",
     "start_time": "2019-08-21T13:44:18.355578Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy : {}'.format(metrics.accuracy_score(y_true=y_test, y_pred=dtc_pred)))\n",
    "print('Precision : {}'.format(metrics.precision_score(y_test, dtc_pred)))\n",
    "print('Recall : {}'.format(metrics.recall_score(y_test, dtc_pred)))\n",
    "print('F1-score : {}'.format(metrics.f1_score(y_test, dtc_pred)))\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, dtc_pred))\n",
    "precision, recall, threshold = metrics.precision_recall_curve(y_test, dtc_pred_proba[:,1])\n",
    "print(\"Precision-Recall AUC: {}\".format(metrics.auc(recall, precision)))\n",
    "print(\"Receiver-Operator AUC: {}\".format(metrics.roc_auc_score(y_test, dtc_pred_proba[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and export your fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T13:44:18.378606Z",
     "start_time": "2019-08-21T13:44:18.375324Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(dtc_fitted, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbclean": true,
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {
    "height": "166px",
    "width": "288px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
