{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First things first\n",
    "*Is everyone familiar with Jupyter notebooks?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:10:26.427404Z",
     "start_time": "2019-08-23T12:10:26.424712Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:36:51.019351Z",
     "start_time": "2019-09-26T15:36:50.331938Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# pip install graphviz\n",
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:36:51.460305Z",
     "start_time": "2019-09-26T15:36:51.457576Z"
    }
   },
   "outputs": [],
   "source": [
    "def hiddenFun(X):\n",
    "    exp = 2;\n",
    "    return X**exp + np.random.randn(X.shape[0])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:36:52.054035Z",
     "start_time": "2019-09-26T15:36:52.051328Z"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 18,\n",
    "                            'lines.linewidth' : 3,\n",
    "                           'figure.figsize' : [15, 5],\n",
    "                           'lines.markersize': 10})\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean to learn?  \n",
    "- process where we take a series of observations \n",
    "- draw conclusions based on past experiences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As humans, we learn from our mistakes\n",
    "\n",
    "For example, \n",
    "- if I take the later bus, \n",
    "- I'm late to work.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning -> we teach a computer to find patterns in data.  \n",
    "\n",
    "\n",
    "Humans are really great at finding patterns, \n",
    "    - but relatively slow at looking through large amounts of data.  \n",
    "    \n",
    "Computers need to be trained to find the patterns, \n",
    "    - but they can process data of the sort of we have (csv files, images, etc) incredibly fast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to leverage machine learning, we need to teach computers to recognize patterns and leverage that ability to solve real world patterns.  \n",
    "\n",
    "Lets start with a really simple 1d example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:38:25.322868Z",
     "start_time": "2019-09-26T15:38:25.126444Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:09:02.239286Z",
     "start_time": "2019-08-23T12:09:02.235007Z"
    }
   },
   "source": [
    "So, \n",
    "- some data $X$ \n",
    "- some corresponding $y$.  \n",
    "\n",
    "We want to model this data, *create a relationship $$f(X) \\approx y $$* \n",
    "where $f$ will represent our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate the predictive relationship by using one of the simplest possible methods, fitting a line to the data $$y=mx+c$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:38:41.128881Z",
     "start_time": "2019-09-26T15:38:40.965515Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def plotBestLine(m,c):\n",
    "    plt.plot(X, y, '.', label='data');\n",
    "    plt.plot(X, m*X + c, label = 'Model: {}x+{}'.format(m,c))\n",
    "    plt.legend();\n",
    "\n",
    "slider_m = FloatSlider(value=1, min=0, max=2, step=0.02, description='Gradient (m)')    \n",
    "slider_c = FloatSlider(value=0, min=-0.5, max=0.5, step=0.02, description='Intercept (c)')    \n",
    "interact(plotBestLine, m=slider_m, c=slider_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:38:55.312864Z",
     "start_time": "2019-09-26T15:38:55.129322Z"
    }
   },
   "outputs": [],
   "source": [
    "p = np.polyfit(X, y, 1)\n",
    "z = np.poly1d(p)\n",
    "plt.plot(X, y, '.')\n",
    "plt.plot(X, z(X), label=r\"Model: ${:.2f}x + {:.2f}$\".format(*p))\n",
    "plt.plot(X, X**2, label=r'Truth')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a model for this data, learned by the computer, namely given an $X$ value (or a bunch of values), we can predict the output.  This example opens up many questions:\n",
    "\n",
    "1. How good is the model?\n",
    "3. Is the model generalizable?\n",
    "4. What does this model teach us about the data?\n",
    "\n",
    "Lets start with question 3, which in many ways is the most important question.  For this simple model we can see that the $y$ vector of labels has a positive correlation with the features $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we do Machine Learning?\n",
    "Normally the goal of machine learning is two-fold\n",
    "\n",
    "1. To understand the data we already have\n",
    "2. Use this understanding to make predictions about unlabeled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning falls into two classes, \n",
    "- **supervised** learning : *learn a predictive relationship between **features** of our data and some sort of output **target** label* \n",
    "- **unsupervised** learning : *find trends in our features without using any target labels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A human example for **Supervised Learning**\n",
    "- borrowing books from a library on mathematics and geography. \n",
    "    - we learn what symbols, images, and words are associated with math,\n",
    "    - maps are associated with geography. \n",
    "\n",
    "**Unsupervised task**\n",
    "- borrow many books without knowing their subject.\n",
    "    - some books contain similar images (maps) \n",
    "    - some books contain similar symbols (e.g. the Greek letters $\\Sigma$ and $\\pi$). \n",
    "    - We say the books containing maps are similar \n",
    "    - Different from the books containing Greek letters. \n",
    "    - **Crucially**, _we do not know what the books are about, only that they are similar or different_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine learning\n",
    "Formally, the supervised machine problem can be stated as:\n",
    "- given a matrix $X$,\n",
    "of dimensions $n \\times p$\n",
    "- create a predictive relationship (or function) $f(X)$ where \\begin{equation} f(X) \\approx y \\end{equation} \n",
    "    - $y$ is a vector of dimension $n$ called the **labels**.\n",
    "    - $X$ is referred to as the **feature matrix** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:39:06.515139Z",
     "start_time": "2019-09-26T15:39:06.492572Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "dt_cali = fetch_california_housing()\n",
    "df_cali = pd.DataFrame(dt_cali.data, columns=dt_cali.feature_names)\n",
    "df_target = [1 if ii < 2 else 0  for ii in dt_cali['target'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:39:25.497929Z",
     "start_time": "2019-09-26T15:39:25.470654Z"
    }
   },
   "outputs": [],
   "source": [
    "numRows = 10\n",
    "df_sup = df_cali.head(numRows)\n",
    "df_sup['-'] = '--------'\n",
    "df_sup['MedianHouseValue'] = dt_cali['target'][:numRows]\n",
    "# df_sup['AffordableHouse'] = df_target[:numRows]\n",
    "print('Supervised Learning Dataset:')\n",
    "df_sup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general goal of supervised learning is to then apply this model to unlabeled data where can build a feature matrix representative of the original.  This allows us to make predictions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:39:27.454570Z",
     "start_time": "2019-09-26T15:39:27.440851Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sup = df_cali.head(numRows+5)[-5:]\n",
    "df_sup['-'] = '--------'\n",
    "df_sup['MedianHouseValue'] = '?'\n",
    "# df_sup['AffordableHouse'] = '?'\n",
    "df_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:39:28.935933Z",
     "start_time": "2019-09-26T15:39:28.923472Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Unsupervised Learning Dataset:')\n",
    "df_cali.head(numRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Difficulties\n",
    "Machine learning is just a tool and is not a 'one-fits-all' solution.\n",
    "\n",
    "Models can be heavily biased and thus not flexible enough to handle generalization.  Let us plot our original function over a larger range and use the model from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:40:05.642639Z",
     "start_time": "2019-09-26T15:40:05.330487Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "X = np.linspace(0, 1, 100)\n",
    "y = X**2 + np.random.randn(X.shape[0])/10\n",
    "p = np.polyfit(X, y, 1)\n",
    "z = np.poly1d(p)\n",
    "ax[0].plot(X, y, '.')\n",
    "ax[0].plot(X, z(X), '-', linewidth=4, label= \"Model: ${:.2f}x + {:.2f}$\".format(*p))\n",
    "ax[0].plot(X, X**2,'-', label=r'Truth')\n",
    "ax[0].legend();\n",
    "ax[0].set_title('Original Model');\n",
    "\n",
    "X = np.linspace(0, 2, 100)\n",
    "y = X**2 + np.random.randn(X.shape[0])/10\n",
    "ax[1].plot(X, y, '.')\n",
    "ax[1].plot(X, z(X), 'g', linewidth=4, label= \"Model: ${:.2f}x + {:.2f}$\".format(*p))\n",
    "ax[1].plot(X, X**2,'-', color='r', label=r'Truth')\n",
    "ax[1].legend();\n",
    "ax[1].set_title('Extending $x$-axis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model works fairly well for the range over which initially considered our data, \n",
    "- but was crap beyond 1\n",
    "- **does not generalize well** \n",
    "\n",
    "This is a general problem; \n",
    "- we should be careful that our training data contains well sampled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:22:58.226586Z",
     "start_time": "2019-08-23T12:22:58.222965Z"
    }
   },
   "source": [
    "\n",
    "**Machine learning finds patterns in data that it's already seen**, and it can't always make good predictions on data it hasn't. \n",
    "\n",
    "Lets try to fix this by adding more parameters to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:40:40.192360Z",
     "start_time": "2019-09-26T15:40:39.958503Z"
    }
   },
   "outputs": [],
   "source": [
    "p = np.polyfit(X, y, 15)\n",
    "z = np.poly1d(p)\n",
    "plt.figure(figsize=[14, 6])\n",
    "plt.plot(X, z(X), 'g', label=r\"${:.2f}x^{{15}} + {:.2f}x^{{14}} + ... + {:.2f}$\".format(*p[[0, 1, -1]]))\n",
    "plt.plot(X, y,'.', label=r'Truth')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow looks like a perfect fit!  Maybe too good?  It looks like the model is fitting little wiggles in the data which we know are not real (the actual data is derived from a simple exponent).  Lets try to generalize again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:40:54.262761Z",
     "start_time": "2019-09-26T15:40:54.065791Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0, 2.5, 100)\n",
    "y = X**2 + np.random.randn(X.shape[0])/10\n",
    "plt.plot(X, z(X), 'g', linewidth=4, label=r\"model\")\n",
    "plt.plot(X, y,'.', label=r'Truth')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow again!  That is pretty bad.  This is an example of overfitting, where we have allowed the model too much flexibility and it has fit the noise in the data which is not generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\" style=\"width: 1500px;\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn more how to combat these issues, but the point is that we need to be careful when choose the model we want to use and the **hyperparameters** (in this case order of the polynomial) for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Scikit-learn` is the most popular Python package for machine learning. \n",
    "- It has a plethora of machine learning models \n",
    "    - a nice and intuitive interface.\n",
    "- creating complicated machine learning workflows very easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning models as classes\n",
    "\n",
    "- `Scikit-learn` relies heavily on object-oriented programming principles\n",
    "- machine learning algorithms as classes\n",
    "\n",
    "In Python, the convention is that class names use CamelCase, the first letter of each word is capitalized. `Scikit-learn` adopts the convention, making it easy to distinguish what is a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:43:32.615480Z",
     "start_time": "2019-09-26T15:43:32.613486Z"
    }
   },
   "outputs": [],
   "source": [
    "#  Implement LinearRegression from Scikit_learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we set `fit_intercept=False`. Here, `fit_intercept` is a **hyperparameter** of the Linear Regression model. Hyperparameters are model parameters that govern the learning process. In terms of hierarchy, they reside \"above\" the regular model parameters. They control what values the model parameters are equal to after undergoing training. They can be easily identified as they are the parameters that are set _prior_ to learning. In `scikit-learn`, hyperparameters are set when creating an instance of the class. The default values that `scikit-learn` uses are *usually* a good set of initial values but this is not always the case. It is important to understand the hyperparameters available and how they affect model performance.\n",
    "\n",
    "`Scikit-learn` refers to machine learning algorithms as **estimators**. There are three different types of estimators: \n",
    "1. Classifiers, \n",
    "1. Regressors, and \n",
    "1. Transformers. \n",
    "\n",
    "Programmatically, `scikit-learn` has a base class called `BaseEstimator` that all estimators inherit. The models inherit an additional class, either `RegressorMixin`, `ClassifierMixin`, and `TransformerMixin`. The inheritance of the second class determines what type of estimator the model represents. We'll divide the estimators into two groups based up on their interface. These two groups are **predictors** and **transformers**.\n",
    "\n",
    "Full information is available in the [documentation](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictors: Classifiers and Regressors\n",
    "\n",
    "As the name suggests, predictors are models that make predictions. There are two main methods.\n",
    "\n",
    "* `fit(X, y)`: trains/fit the object to the feature matrix $X$ and label vector $y$.\n",
    "* `predict(X)`: makes predictions on the passed data set $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:27:25.940534Z",
     "start_time": "2019-08-23T12:27:25.827621Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create model and train/fit\n",
    "\n",
    "## use linear regression\n",
    "## fit on (df_cali, df_target)\n",
    "## predict label values on X: predict(df_cali)\n",
    "\n",
    "print(\"Prediction : {}\".format(y_pred))\n",
    "print(\"     Shape of the prediction array: {}\".format(y_pred.shape))\n",
    "print(\"     Shape of the training set: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the output of `predict(X)` is a NumPy array of one dimension. The array has the same size as the number of rows of the data that was passed to the `predict` method. \n",
    "\n",
    "Since we are using linear regression and our data has eight features, our model is\n",
    "\n",
    "$$ y(X) = \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\beta_5 x_5 + \\beta_6 x_6 + \\beta_7 x_7 + \\beta_8 x_8 + \\beta_0. $$\n",
    "\n",
    "The coefficients are stored in the fitted model as an object's attribute. `Scikit-learn` adopts a convention where all attributes that are determined/calculated _after_ fitting end in an underscore. The model coefficients and intercept are retrieved using the `coefs_` and the `intercept_` attributes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:28:25.456437Z",
     "start_time": "2019-08-23T12:28:25.452252Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"β_0: {}\".format(model.intercept_))\n",
    "for i in range(8):\n",
    "    print(\"β_{}: {}\".format(i+1, model.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T09:31:11.900465Z",
     "start_time": "2019-08-20T09:31:11.895710Z"
    }
   },
   "source": [
    "If we wanted to know how well the model performs making predictions with a data set, we can use the `score(X, y)` method. It works by\n",
    "\n",
    "1. Internally running `predict(X)` to produce predicted values.\n",
    "1. Using the predicted values to evaluate the model compared to the true label values that were passed to the method.\n",
    "\n",
    "The evaluation equation varies depending if the model is a regressor or classifier. For regression, it is the $R^2$ value while for classification, it is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:28:58.311153Z",
     "start_time": "2019-08-23T12:28:58.302119Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"R^2: {:g}\".format(model.score(df_cali, df_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a rather simple model, linear regression. What if we wanted to use a more complicated model? All we need to do is an easy substitution; there is minimum code rewrite as the models have the same interface. Of course, different models have different hyperparameters so we need to be careful when swapping out algorithms. Let's use a more complicated model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:51:19.569420Z",
     "start_time": "2019-08-23T08:51:18.516449Z"
    }
   },
   "outputs": [],
   "source": [
    "## use GradientBoostingRegressor\n",
    "## fit(df_cali, df_target)\n",
    "## predict(df_cali)\n",
    "\n",
    "print(y_pred)\n",
    "print(\"R^2: {:g}\".format(model.score(df_cali, df_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "Transformers are models that process and transform a data set. These transformers are very useful because rarely is our data in a form to feed directly to a machine learning model for both training and predicting. All transformers have the same interface:\n",
    "\n",
    "* `fit(X)`: trains/fits the object to the feature matrix $X$.\n",
    "* `transform(X)`: applies the transformation on $X$ using any parameters learned\n",
    "* `fit_transform(X)`: applies both `fit(X)` and then `transform(X)`.\n",
    "\n",
    "Let's demonstrate transformers with `StandardScaler`, which scales each feature to have zero mean and unit variance. The transformed feature $x'_i$ is equal to\n",
    "\\begin{equation} x'_i = \\frac{x_i - \\mu_i}{\\sigma_i} \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:30:33.953094Z",
     "start_time": "2019-08-23T12:30:33.951022Z"
    }
   },
   "outputs": [],
   "source": [
    "## use StandardScaler\n",
    "## .fit(df_cali)\n",
    "## Xt = scaler.transform(df_cali)\n",
    "\n",
    "\n",
    "\n",
    "# # create data frame with results\n",
    "# stats = np.vstack((df_cali.mean(axis=0), df_cali.var(axis=0), Xt.mean(axis=0), Xt.var(axis=0))).T\n",
    "# feature_names = df_cali.columns\n",
    "# columns = ['unscaled mean', 'unscaled variance', 'scaled mean', 'scaled variance']\n",
    "\n",
    "# pd.DataFrame(stats, index=feature_names, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame shows how our features have wildly different scales; the average population is over 1000 but the average room is slightly over 5. Now, our features each have zero mean and a variance of one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning for a Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Titanic Likelihood of Survival \n",
    "For this notebook, we will use the [Titanic Likelihood of Survival](https://www.kaggle.com/c/titanic/data) data. The data set contains the likelihood of survival of a person on board of the titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:30:38.268363Z",
     "start_time": "2019-08-23T12:30:38.258663Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('./00_data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:30:38.449721Z",
     "start_time": "2019-08-23T12:30:38.436804Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_titanic.shape)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data dictionary**\n",
    "\n",
    "| Variable\t| Definition|\tKey |\n",
    "|---|---|---|\n",
    "|survived |\tSurvival |\t0 = No, 1 = Yes|\n",
    "|pclass |\tTicket class |\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|sex \t|Sex \t||\n",
    "|Age |\tAge in years \t||\n",
    "|sibsp \t|# of siblings / spouses aboard the Titanic \t||\n",
    "|parch \t|# of parents / children aboard the Titanic \t||\n",
    "|ticket \t|Ticket number \t||\n",
    "|fare \t|Passenger fare \t||\n",
    "|cabin |\tCabin number \t||\n",
    "|embarked |\tPort of Embarkation |\tC = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "**Variable Notes**\n",
    "- *pclass* : A proxy for socio-economic status\n",
    "    - 1st = Upper\n",
    "    - 2nd = Middle\n",
    "    - 3rd = Lower\n",
    "- *age* : Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "- *sibsp* : The dataset defines family relations in this way...\n",
    "    - Sibling = brother, sister, stepbrother, stepsister\n",
    "    - Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "- *parch* : The dataset defines family relations in this way...\n",
    "    - Parent = mother, father\n",
    "    - Child = daughter, son, stepdaughter, stepson\n",
    "    - Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematics of supervised learning\n",
    "\n",
    "For supervised ML, our model receives a vector of **features**, $X$, and maps it to some predicted label, $y$. In order to train our model, we will need many **observations** (i.e. measurements) and their associated labels. We can assemble these observations into a matrix.\n",
    "$$ f(X_{ij}) \\approx y_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:30:45.448039Z",
     "start_time": "2019-08-23T12:30:45.436013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T09:50:12.851553Z",
     "start_time": "2019-08-20T09:50:12.846378Z"
    }
   },
   "source": [
    "In the above dataframe, each column is a feature (i.e. a variable) and each row is an observation (i.e. a measurement). Said another way, things like **pclass**, **sex** and **age** are features. The column **survived** is the target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Classification Problems\n",
    "- In classification, we predict categorical labels. \n",
    "- In regression, we predict quantitative/numerical labels.\n",
    "\n",
    "The critical difference is that we can't take a difference between the predicted and actual category in classification. \n",
    "\n",
    "We are trying to determine the model $f$ that can best describes the relationship\n",
    "\n",
    "$$ y_j = f(X_j). $$\n",
    "\n",
    "For classification, \n",
    "- $y_j$ can only take a finite set of values. \n",
    "\n",
    "If there are only two such values, \n",
    "- we are dealing with **binary** classification. \n",
    "\n",
    "Examples:\n",
    "- **binary classification**: predicting whether it will rain or not.\n",
    "- **multiclass classification**: image classification when we are trying to identify an image if it is of a person, a road sign, a car, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:00:12.380074Z",
     "start_time": "2019-08-20T10:00:12.374107Z"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "- A natural choice \n",
    "- number of observations  correctly classified over all observations. \n",
    "\n",
    "For example, \n",
    "- if your model properly identified 77 out of 100 images, \n",
    "    - you have an accuracy of 77%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, it is simply\n",
    "\n",
    "$$ \\frac{\\text{number of correct observations}}{\\text{number of observations}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, accuracy may not always be a good metric. \n",
    "\n",
    "Consider the case of disease detection:\n",
    "    - only 10% of the observations have the disease. \n",
    "    \n",
    "    \n",
    "A \"stupid\" classifier that always predicts all as \"No disease\",\n",
    "\n",
    "\\begin{align}\n",
    "\\text{True Label} &: \\left[0,0,0,0,0,0,0,0,0,0,0,...,0,1,1,1,1,1,1,1,1,1,1\\right]\\\\\n",
    "\\text{Predicted } &: \\left[0,0,0,0,0,0,0,0,0,0,0,...,0,0,0,0,0,0,0,0,0,0,0\\right] \\\\\n",
    "\\\\\n",
    "\\frac{\\text{number of correct observations}}{\\text{number of observations}}\n",
    "&= \\frac{90}{100} = 90\\%\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Realistically, this model has learning \"nothing\"* as it fails to identify any person with the disease. \n",
    "\n",
    "We need a metric that will tell us how well our model performs for a particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, f1-Score and Confustion Matrix\n",
    "####  Precision & Recall\n",
    "For the example of disease detection, \n",
    "- we are more interested in determining our model's performance with regards to the class representing having the disease. Let's call this class  **positive** and not having the disease as **negative**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know:\n",
    "- fraction of infected that were actually infected\n",
    "- fraction of infected incorrectly identified\n",
    "    - **precision** and **recall**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**: how \"precise\" our model was with regards to labeling observations as positive. \n",
    "\n",
    "**Recall**: model's ability to \"catch\" and properly label observations that are positive.\n",
    "\n",
    "To summarize these 2 metrics, we construct a **confusion matrix**. This is a table summarizing the performance of the model by enumerating true and false positives and the true and false negatives.\n",
    "\n",
    "\n",
    "|             *       | Positive Observation (1)   | Negative Observation (0)   |\n",
    "|---------------------|:------------------------:|:-----------------------:|\n",
    "| Positive Prediction (1) |     True Positive (TP)   | False Positive (FP)     |\n",
    "| Negative Prediction (0) | False Negative (FN)      |     True Negative (TN)  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the definitions used earlier, the equation for precision and recall are\n",
    "\n",
    "$$ \\text{precision} = \\frac{\\text{TP}}{TP + FP}$$\n",
    "and\n",
    "$$ \\text{recall} = \\frac{\\text{TP}}{TP + FN}. $$\n",
    "\n",
    "Note, the difference between the metrics is their denominator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*precision will be along the horizontal*\n",
    "\n",
    "*recall will be vertical*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our disease detection example, if our data had 10 observations as true disease, \n",
    "\n",
    "\\begin{align}\n",
    "\\text{True Label} &: \\left[1,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1\\right] \\\\\n",
    "\\text{Predicted}  & :\\left[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0\\right] \\\\\n",
    "\\\\\n",
    "\\text{12 observations were marked as infected} & \\\\\n",
    "\\text{precision} & = \\frac{\\text{TP}}{TP + FP} = \\frac{8}{8+4} = 0.667\\% \\\\\n",
    "\\\\\n",
    "\\text{8 were correctly identified or \"recalled\"} &\\\\\n",
    "\\text{recall} &= \\frac{\\text{TP}}{TP + FN} = \\frac{8}{8+2} = 0.80\\%\n",
    "\\end{align}\n",
    "\n",
    "If we had used the previous \"simple\" model that predicts the all as 0 class, the recall would be 0 and our precision would be undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* For disease detection, is it better to have a higher precision or recall?\n",
    "****\n",
    "* Does our answer change if we need to have diagnosed patients undergo invasive and risky procedures?\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:01:27.571761Z",
     "start_time": "2019-08-20T10:01:27.567758Z"
    }
   },
   "source": [
    "#### f1-Score\n",
    "In addition to precision and recall, there is that f1-score which is the harmonic mean of precision and recall. It is a nice metric to use when we don't have a preference over precision and recall. \n",
    "$$ \\text{f1-score} = 2\\times\\frac{\\text{precision}\\times\\text{recall}}{\\text{precision}+\\text{recall}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report\n",
    "We can easily calculate all these metrics using the `sklearn.metrics` module and to summarise all metrics, we will use the function `metrics.classification_report`. This will calculate the metrics for both scenarios of what class is considered positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:41:09.118820Z",
     "start_time": "2019-08-23T12:41:09.113423Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# generate our results\n",
    "y_pred = np.zeros(100, dtype=np.int32)\n",
    "y_pred[:12] = 1\n",
    "y = np.zeros(100)\n",
    "y[:8] = 1\n",
    "y[-2:] = 1\n",
    "\n",
    "print('True Labels : ')\n",
    "print([int(ii) for ii in y])\n",
    "print('\\nPredicted Labels :')\n",
    "print([int(ii) for ii in y_pred])\n",
    "\n",
    "\n",
    "## calculate precision_score(y,y_pred), recall_score(y, y_pred))), classification_report(y, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nPrecision: {:g}\".format())\n",
    "# print(\"Recall: {:g}\".format())\n",
    "# print(\"Classification Report:\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Classification Models\n",
    "Some classification models do not directly predict a class for an observation but instead reports a probability.\n",
    "\n",
    "For example, \n",
    "- it might predict that there's a 75% patient has disease.\n",
    "\n",
    "The natural choice is to assign the observation as 1 since the predicted probability is greater than 50%.\n",
    "\n",
    "However, we don't have to stick to 50%; \n",
    "- we can adjust our **threshold** \n",
    "- classify observations as positive if our models predicts a greater than 90% probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the threshold, \n",
    "- we will make our model only make positive predictions when it is very certain and confident. \n",
    "if we lower our threshold, \n",
    "- our model will more liberally assign positive labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is tradeoff between precision and recall that becomes more apparent with probabilistic models. Let's explore and visualize the tradeoff between precision and recall. We'll generate some data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:43:36.696178Z",
     "start_time": "2019-08-23T12:43:36.691434Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "np.random.seed(0)\n",
    "y_proba = np.linspace(0, 1, 1000)\n",
    "y_pred = (y_proba > 0.5).astype(np.int32)\n",
    "y = np.random.binomial(1, y_proba)\n",
    "\n",
    "print(\"accuracy: {}\".format(metrics.accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:43:43.675469Z",
     "start_time": "2019-08-23T12:43:43.486646Z"
    }
   },
   "outputs": [],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(y, y_proba)\n",
    "f1_score = 2*precision*recall/(precision + recall)\n",
    "threshold = np.hstack((0, threshold))\n",
    "\n",
    "plt.plot(threshold, precision)\n",
    "plt.plot(threshold, recall)\n",
    "plt.plot(threshold, f1_score)\n",
    "plt.xlabel('threshold')\n",
    "plt.legend(['precision', 'recall', '$F_1$']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, \n",
    "- increasing the threshold led to higher precision but lower recall. \n",
    "- largest $F_1$ score was about 0.36 threshold\n",
    "\n",
    "Any probabilistic model\n",
    "- can achieve any arbitrary level of precision and recall by adjusting the threshold.\n",
    "\n",
    "\n",
    "**we need a single metric that is not dependent on threshold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the curve\n",
    "The precision-recall curve illustrates the tradeoff for a particular classifier. While there will always be a tradeoff between these two metrics, ideally the tradeoff should not be severe. In other words, the model should not sacrifice a large amount of precision to slightly improve recall. We can visualize the degree of the tradeoff by plotting what is known as a precision-recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:44:57.605824Z",
     "start_time": "2019-08-23T12:44:57.455641Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:02:29.415011Z",
     "start_time": "2019-08-20T10:02:29.409750Z"
    }
   },
   "source": [
    "Geometrically, it is better to have a model with a larger area under the curve, **AUC**, of its precision-recall plot. \n",
    "\n",
    "In `scikit-learn`, the AUC can be calculated using the `metrics.auc` function. \n",
    "\n",
    "In addition to **AUC**, \n",
    "- **ROC-AUC**: receiver-operator curve (ROC) - true positive rate against the false negative rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T12:46:24.243060Z",
     "start_time": "2019-08-23T12:46:24.238215Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Precision-Recall AUC: {}\".format(metrics.auc(recall, precision)))\n",
    "print(\"Receiver-Operator AUC: {}\".format(metrics.roc_auc_score(y, y_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, the resulting model had similar values for AUC and ROC. In general, if your data is imbalanced (more observation of the negative class) or if you care more about false positives you should rely on AUC of the precision-recall curve. Note, the number of true negatives are not factored in calculating either precision or recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "1. What is ML\n",
    "1. How to use `scikit-learn`\n",
    "    - **predictors**: `fit(X)`, `predict(X)`\n",
    "    - **transformers**: `fit(X)`, `transform(X)`,`fit_transform(X)`\n",
    "1. What metrics to use for Supervised classification learning    \n",
    "    - Accuracy,\n",
    "    - Precision, Recall, f1-score\n",
    "    - Confusion Matrix/Classification Report\n",
    "    - Area under curve (AUC)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbclean": true,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "166px",
    "width": "288px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
